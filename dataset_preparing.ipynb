{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yapd0DPyggbY"
   },
   "source": [
    "## Установка пакетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T22:15:22.610954Z",
     "start_time": "2021-04-14T22:15:15.212525Z"
    },
    "id": "XSfotHD2SlDv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (3.0.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from spacy) (0.7.4)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from spacy) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from spacy) (1.19.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from spacy) (1.7.3)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from spacy) (0.3.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from spacy) (2.24.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kirill_sergeev\\appdata\\roaming\\python\\python38\\site-packages (from spacy) (54.1.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from spacy) (2.4.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.0 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from spacy) (3.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from spacy) (0.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kirill_sergeev\\appdata\\roaming\\python\\python38\\site-packages (from spacy) (20.9)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.2 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from spacy) (8.0.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from spacy) (2.0.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from spacy) (2.0.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kirill_sergeev\\appdata\\roaming\\python\\python38\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from spacy) (4.50.2)\n",
      "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy) (3.0.0)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.11)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\kirill_sergeev\\appdata\\roaming\\python\\python38\\site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\kirill_sergeev\\appdata\\roaming\\python\\python38\\site-packages (from jinja2->spacy) (1.1.1)\n",
      "Requirement already satisfied: en-core-web-sm==3.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl#egg=en_core_web_sm==3.0.0 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: spacy<3.1.0,>=3.0.0 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.0 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kirill_sergeev\\appdata\\roaming\\python\\python38\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (54.1.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.0.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.8.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.7.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kirill_sergeev\\appdata\\roaming\\python\\python38\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (20.9)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.7.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.24.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kirill_sergeev\\appdata\\roaming\\python\\python38\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.11.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.50.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.19.2)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.3.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.5)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.2 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (8.0.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\kirill_sergeev\\appdata\\roaming\\python\\python38\\site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2020.6.20)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\kirill_sergeev\\appdata\\roaming\\python\\python38\\site-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.1.1)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (7.1.2)\n",
      "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in c:\\users\\kirill_sergeev\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.0)\n",
      "[!] As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the full\n",
      "pipeline package name 'en_core_web_sm' instead.\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-15 01:15:18.033308: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2021-04-15 01:15:18.033329: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# Install spaCy (run in terminal/prompt)\n",
    "import sys\n",
    "!{sys.executable} -m pip install spacy\n",
    "# Download spaCy's  'en' Model\n",
    "!{sys.executable} -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T22:15:22.703706Z",
     "start_time": "2021-04-14T22:15:22.688747Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C6VO9Tz9vHFr",
    "outputId": "c816a0dd-aa81-4682-e67e-c5458fd83179"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Kirill_Sergeev\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Kirill_Sergeev\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wOMpOa3oglGx"
   },
   "source": [
    "## Импорт зависимостей, константы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T22:17:42.131624Z",
     "start_time": "2021-04-14T22:17:42.113672Z"
    },
    "id": "yA4FomGit-2q"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "from nltk.stem import *\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer, EnglishStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T22:17:42.522495Z",
     "start_time": "2021-04-14T22:17:42.508540Z"
    },
    "id": "GtPXY-KzkB49"
   },
   "outputs": [],
   "source": [
    "LANGUAGE = 'english'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pGN1OvbvY543"
   },
   "source": [
    "## Подготовка данных, лемматизация, стеминг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T22:17:43.676442Z",
     "start_time": "2021-04-14T22:17:43.323402Z"
    },
    "id": "41uxIWtckB5M"
   },
   "outputs": [],
   "source": [
    "stemmer = EnglishStemmer()\n",
    "lemmatizer = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T22:17:43.784154Z",
     "start_time": "2021-04-14T22:17:43.775178Z"
    },
    "id": "8devZ06KkB5M"
   },
   "outputs": [],
   "source": [
    "custom_stop_words = ['assume', 'never', 'nt', 'always', 'often', 'want', 'wonder', 'yeah', 'yes', 'know', 'like', 'nice', 'good', 'think', 'would', 'also', 'get', 'make', 'one', 'probably', 'maybe']\n",
    "\n",
    "lang_stopwords = stopwords.words(LANGUAGE)\n",
    "lang_stopwords.extend(['©', '…', '«', '»', '...', '- -', '--', '-', '_'])\n",
    "lang_stopwords.extend(custom_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T22:17:44.325848Z",
     "start_time": "2021-04-14T22:17:44.306899Z"
    },
    "id": "C_lTTDVNzric"
   },
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    url_check = \"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\"\n",
    "    clean = re.sub(url_check, \"\", text)\n",
    "    return clean\n",
    "\n",
    "def replace_copywrite(text):\n",
    "  check = \"©\\s?(?:\\d{4}|\\D{2})[^.]{1,}.\"\n",
    "  clean = re.sub(check, \"\", text)\n",
    "\n",
    "  return clean\n",
    "\n",
    "def remove_numbers(text):\n",
    "    num_check = \"([0-9,]*)\"\n",
    "    clean = re.sub(num_check, \"\", text).strip()\n",
    "    return clean\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return \"\".join([ch if ch not in string.punctuation else ' ' for ch in text])\n",
    "\n",
    "def remove_multiple_spaces(text):\n",
    "    return re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    tokens = word_tokenize(text) \n",
    "    tokens = [token for token in tokens if token not in lang_stopwords and token != ' ']\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T22:17:44.827366Z",
     "start_time": "2021-04-14T22:17:44.818389Z"
    },
    "id": "lwynuQPwYUaH"
   },
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    text_lem = lemmatizer(text)\n",
    "    tokens = [token.lemma_ for token in text_lem if token.lemma_ != ' ' and token.lemma_ not in lang_stopwords]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "def stemming_text(text):\n",
    "    tokens = word_tokenize(text)    \n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return \" \".join(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T22:17:45.389676Z",
     "start_time": "2021-04-14T22:17:45.377708Z"
    },
    "id": "VNVKlFU6kB5P"
   },
   "outputs": [],
   "source": [
    "def clean_df_series(df_series):\n",
    "\n",
    "  clean_series = df_series.map(lambda x: x.lower())\n",
    "  clean_series = clean_series.map(remove_url)\n",
    "  clean_series = clean_series.map(remove_punctuation)\n",
    "  clean_series = clean_series.map(remove_numbers)\n",
    "  clean_series = clean_series.map(remove_stop_words)\n",
    "  clean_series = clean_series.apply(lambda x: \" \".join([w for w in x.split() if (len(w)>2)]))\n",
    "  clean_series = clean_series.apply(lambda x: \" \".join([w for w in x.split() if (len(set(w))>2)]))\n",
    "  clean_series = clean_series.map(remove_multiple_spaces)\n",
    "  \n",
    "  return clean_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JzUSbw4ugw8O"
   },
   "source": [
    "## Работа с датасетом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T22:19:39.737435Z",
     "start_time": "2021-04-14T22:19:39.705521Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "tnPjnLEig0Gn",
    "outputId": "49b6297c-8611-4af6-bf74-89728e7d5441"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>agent</th>\n",
       "      <th>message</th>\n",
       "      <th>topic</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>agent_1</td>\n",
       "      <td>do you listen to albums?</td>\n",
       "      <td>Music</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>agent_2</td>\n",
       "      <td>Yes I do. Have you listened to Hybrid Theory?</td>\n",
       "      <td>Music</td>\n",
       "      <td>do you listen to albums?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>agent_1</td>\n",
       "      <td>Yes it is the best selling album of the centur...</td>\n",
       "      <td>Music</td>\n",
       "      <td>do you listen to albums? \\n Yes I do. Have you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>agent_2</td>\n",
       "      <td>True. Do you know who Reel Big FIsh are?</td>\n",
       "      <td>Music</td>\n",
       "      <td>Yes I do. Have you listened to Hybrid Theory? ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>agent_1</td>\n",
       "      <td>Yes the band that lost the rights to their own...</td>\n",
       "      <td>Music</td>\n",
       "      <td>Yes it is the best selling album of the centur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>1157</td>\n",
       "      <td>54</td>\n",
       "      <td>agent_1</td>\n",
       "      <td>I’d like to visit you this summer  perhaps in...</td>\n",
       "      <td>Weather_Time</td>\n",
       "      <td>Of course  it rains sometimes  but I still li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>1158</td>\n",
       "      <td>54</td>\n",
       "      <td>agent_2</td>\n",
       "      <td>I think by summer I’ll pass all my exams so I...</td>\n",
       "      <td>Weather_Time</td>\n",
       "      <td>It’s fine and I feel comfortable. \\n  I’d lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>1159</td>\n",
       "      <td>54</td>\n",
       "      <td>agent_1</td>\n",
       "      <td>I’m also well  thank you! I like it here  tho...</td>\n",
       "      <td>Weather_Time</td>\n",
       "      <td>I’d like to visit you this summer  perhaps in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>1160</td>\n",
       "      <td>54</td>\n",
       "      <td>agent_2</td>\n",
       "      <td>You know  I’m a Spanish guy.</td>\n",
       "      <td>Weather_Time</td>\n",
       "      <td>I think by summer I’ll pass all my exams so I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>1161</td>\n",
       "      <td>54</td>\n",
       "      <td>agent_1</td>\n",
       "      <td>I like the sun and heat.</td>\n",
       "      <td>Weather_Time</td>\n",
       "      <td>I’m also well  thank you! I like it here  tho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1151 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      utterance_id  conversation_id     agent  \\\n",
       "0                0                0   agent_1   \n",
       "1                1                0   agent_2   \n",
       "2                2                0   agent_1   \n",
       "3                3                0   agent_2   \n",
       "4                4                0   agent_1   \n",
       "...            ...              ...       ...   \n",
       "1146          1157               54   agent_1   \n",
       "1147          1158               54   agent_2   \n",
       "1148          1159               54   agent_1   \n",
       "1149          1160               54   agent_2   \n",
       "1150          1161               54   agent_1   \n",
       "\n",
       "                                                message         topic  \\\n",
       "0                              do you listen to albums?         Music   \n",
       "1         Yes I do. Have you listened to Hybrid Theory?         Music   \n",
       "2     Yes it is the best selling album of the centur...         Music   \n",
       "3              True. Do you know who Reel Big FIsh are?         Music   \n",
       "4     Yes the band that lost the rights to their own...         Music   \n",
       "...                                                 ...           ...   \n",
       "1146   I’d like to visit you this summer  perhaps in...  Weather_Time   \n",
       "1147   I think by summer I’ll pass all my exams so I...  Weather_Time   \n",
       "1148   I’m also well  thank you! I like it here  tho...  Weather_Time   \n",
       "1149                       You know  I’m a Spanish guy.  Weather_Time   \n",
       "1150                           I like the sun and heat.  Weather_Time   \n",
       "\n",
       "                                                context  \n",
       "0                                                        \n",
       "1                              do you listen to albums?  \n",
       "2     do you listen to albums? \\n Yes I do. Have you...  \n",
       "3     Yes I do. Have you listened to Hybrid Theory? ...  \n",
       "4     Yes it is the best selling album of the centur...  \n",
       "...                                                 ...  \n",
       "1146   Of course  it rains sometimes  but I still li...  \n",
       "1147   It’s fine and I feel comfortable. \\n  I’d lik...  \n",
       "1148   I’d like to visit you this summer  perhaps in...  \n",
       "1149   I think by summer I’ll pass all my exams so I...  \n",
       "1150   I’m also well  thank you! I like it here  tho...  \n",
       "\n",
       "[1151 rows x 6 columns]"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('DATA2.csv')\n",
    "# data.dropna(subset=['abstract'], inplace=True)\n",
    "data.fillna(\"\", inplace=True)\n",
    "\n",
    "# data['message+context'] = data['title'] + \" \" + data['abstract']\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T22:19:49.251085Z",
     "start_time": "2021-04-14T22:19:44.148915Z"
    }
   },
   "outputs": [],
   "source": [
    "data['text_with_context'] = data['message'] + data['context']\n",
    "data['text_without_context'] = data['message']\n",
    "    \n",
    "data['text_with_context_clean'] = clean_df_series(data['text_with_context'])\n",
    "data['text_with_context_lemm'] = data['text_with_context_clean'].map(lemmatize_text)\n",
    "data['text_with_context_lemm'] = data['text_with_context_lemm'].map(remove_stop_words)\n",
    "\n",
    "data['text_without_context_clean'] = clean_df_series(data['text_without_context'])\n",
    "data['text_without_context_lemm'] = data['text_without_context_clean'].map(lemmatize_text)\n",
    "data['text_without_context_lemm'] = data['text_without_context_lemm'].map(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T22:19:52.733220Z",
     "start_time": "2021-04-14T22:19:52.711278Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>agent</th>\n",
       "      <th>message</th>\n",
       "      <th>topic</th>\n",
       "      <th>context</th>\n",
       "      <th>text_with_context</th>\n",
       "      <th>text_without_context</th>\n",
       "      <th>text_with_context_clean</th>\n",
       "      <th>text_with_context_lemm</th>\n",
       "      <th>text_without_context_clean</th>\n",
       "      <th>text_without_context_lemm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>agent_1</td>\n",
       "      <td>do you listen to albums?</td>\n",
       "      <td>Music</td>\n",
       "      <td></td>\n",
       "      <td>do you listen to albums?</td>\n",
       "      <td>do you listen to albums?</td>\n",
       "      <td>listen albums</td>\n",
       "      <td>listen album</td>\n",
       "      <td>listen albums</td>\n",
       "      <td>listen album</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>agent_2</td>\n",
       "      <td>Yes I do. Have you listened to Hybrid Theory?</td>\n",
       "      <td>Music</td>\n",
       "      <td>do you listen to albums?</td>\n",
       "      <td>Yes I do. Have you listened to Hybrid Theory?d...</td>\n",
       "      <td>Yes I do. Have you listened to Hybrid Theory?</td>\n",
       "      <td>listened hybrid theory listen albums</td>\n",
       "      <td>listen hybrid theory listen album</td>\n",
       "      <td>listened hybrid theory</td>\n",
       "      <td>listen hybrid theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>agent_1</td>\n",
       "      <td>Yes it is the best selling album of the centur...</td>\n",
       "      <td>Music</td>\n",
       "      <td>do you listen to albums? \\n Yes I do. Have you...</td>\n",
       "      <td>Yes it is the best selling album of the centur...</td>\n",
       "      <td>Yes it is the best selling album of the centur...</td>\n",
       "      <td>best selling album century alldo listen albums...</td>\n",
       "      <td>selling album century alldo listen album liste...</td>\n",
       "      <td>best selling album century</td>\n",
       "      <td>selling album century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>agent_2</td>\n",
       "      <td>True. Do you know who Reel Big FIsh are?</td>\n",
       "      <td>Music</td>\n",
       "      <td>Yes I do. Have you listened to Hybrid Theory? ...</td>\n",
       "      <td>True. Do you know who Reel Big FIsh are?Yes I ...</td>\n",
       "      <td>True. Do you know who Reel Big FIsh are?</td>\n",
       "      <td>true reel big fish listened hybrid theory best...</td>\n",
       "      <td>true reel big fish listen hybrid theory sellin...</td>\n",
       "      <td>true reel big fish</td>\n",
       "      <td>true reel big fish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>agent_1</td>\n",
       "      <td>Yes the band that lost the rights to their own...</td>\n",
       "      <td>Music</td>\n",
       "      <td>Yes it is the best selling album of the centur...</td>\n",
       "      <td>Yes the band that lost the rights to their own...</td>\n",
       "      <td>Yes the band that lost the rights to their own...</td>\n",
       "      <td>band lost rights music sadyes best selling alb...</td>\n",
       "      <td>band lose right music sadye selling album cent...</td>\n",
       "      <td>band lost rights music sad</td>\n",
       "      <td>band lose right music sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>1157</td>\n",
       "      <td>54</td>\n",
       "      <td>agent_1</td>\n",
       "      <td>I’d like to visit you this summer  perhaps in...</td>\n",
       "      <td>Weather_Time</td>\n",
       "      <td>Of course  it rains sometimes  but I still li...</td>\n",
       "      <td>I’d like to visit you this summer  perhaps in...</td>\n",
       "      <td>I’d like to visit you this summer  perhaps in...</td>\n",
       "      <td>visit summer perhaps middle july convenient en...</td>\n",
       "      <td>visit summer perhaps middle july convenient en...</td>\n",
       "      <td>visit summer perhaps middle july convenient en...</td>\n",
       "      <td>visit summer perhaps middle july convenient en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>1158</td>\n",
       "      <td>54</td>\n",
       "      <td>agent_2</td>\n",
       "      <td>I think by summer I’ll pass all my exams so I...</td>\n",
       "      <td>Weather_Time</td>\n",
       "      <td>It’s fine and I feel comfortable. \\n  I’d lik...</td>\n",
       "      <td>I think by summer I’ll pass all my exams so I...</td>\n",
       "      <td>I think by summer I’ll pass all my exams so I...</td>\n",
       "      <td>summer pass exams lot free time fine feel comf...</td>\n",
       "      <td>summer pass exam lot free time fine feel comfo...</td>\n",
       "      <td>summer pass exams lot free time</td>\n",
       "      <td>summer pass exam lot free time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>1159</td>\n",
       "      <td>54</td>\n",
       "      <td>agent_1</td>\n",
       "      <td>I’m also well  thank you! I like it here  tho...</td>\n",
       "      <td>Weather_Time</td>\n",
       "      <td>I’d like to visit you this summer  perhaps in...</td>\n",
       "      <td>I’m also well  thank you! I like it here  tho...</td>\n",
       "      <td>I’m also well  thank you! I like it here  tho...</td>\n",
       "      <td>well thank though gets chilly humid sometimes ...</td>\n",
       "      <td>well thank though chilly humid sometimes visit...</td>\n",
       "      <td>well thank though gets chilly humid sometimes</td>\n",
       "      <td>well thank though chilly humid sometimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>1160</td>\n",
       "      <td>54</td>\n",
       "      <td>agent_2</td>\n",
       "      <td>You know  I’m a Spanish guy.</td>\n",
       "      <td>Weather_Time</td>\n",
       "      <td>I think by summer I’ll pass all my exams so I...</td>\n",
       "      <td>You know  I’m a Spanish guy. I think by summe...</td>\n",
       "      <td>You know  I’m a Spanish guy.</td>\n",
       "      <td>spanish guy summer pass exams lot free time we...</td>\n",
       "      <td>spanish guy summer pass exam lot free time wel...</td>\n",
       "      <td>spanish guy</td>\n",
       "      <td>spanish guy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>1161</td>\n",
       "      <td>54</td>\n",
       "      <td>agent_1</td>\n",
       "      <td>I like the sun and heat.</td>\n",
       "      <td>Weather_Time</td>\n",
       "      <td>I’m also well  thank you! I like it here  tho...</td>\n",
       "      <td>I like the sun and heat. I’m also well  thank...</td>\n",
       "      <td>I like the sun and heat.</td>\n",
       "      <td>sun heat well thank though gets chilly humid s...</td>\n",
       "      <td>sun heat well thank though chilly humid someti...</td>\n",
       "      <td>sun heat</td>\n",
       "      <td>sun heat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1151 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      utterance_id  conversation_id     agent  \\\n",
       "0                0                0   agent_1   \n",
       "1                1                0   agent_2   \n",
       "2                2                0   agent_1   \n",
       "3                3                0   agent_2   \n",
       "4                4                0   agent_1   \n",
       "...            ...              ...       ...   \n",
       "1146          1157               54   agent_1   \n",
       "1147          1158               54   agent_2   \n",
       "1148          1159               54   agent_1   \n",
       "1149          1160               54   agent_2   \n",
       "1150          1161               54   agent_1   \n",
       "\n",
       "                                                message         topic  \\\n",
       "0                              do you listen to albums?         Music   \n",
       "1         Yes I do. Have you listened to Hybrid Theory?         Music   \n",
       "2     Yes it is the best selling album of the centur...         Music   \n",
       "3              True. Do you know who Reel Big FIsh are?         Music   \n",
       "4     Yes the band that lost the rights to their own...         Music   \n",
       "...                                                 ...           ...   \n",
       "1146   I’d like to visit you this summer  perhaps in...  Weather_Time   \n",
       "1147   I think by summer I’ll pass all my exams so I...  Weather_Time   \n",
       "1148   I’m also well  thank you! I like it here  tho...  Weather_Time   \n",
       "1149                       You know  I’m a Spanish guy.  Weather_Time   \n",
       "1150                           I like the sun and heat.  Weather_Time   \n",
       "\n",
       "                                                context  \\\n",
       "0                                                         \n",
       "1                              do you listen to albums?   \n",
       "2     do you listen to albums? \\n Yes I do. Have you...   \n",
       "3     Yes I do. Have you listened to Hybrid Theory? ...   \n",
       "4     Yes it is the best selling album of the centur...   \n",
       "...                                                 ...   \n",
       "1146   Of course  it rains sometimes  but I still li...   \n",
       "1147   It’s fine and I feel comfortable. \\n  I’d lik...   \n",
       "1148   I’d like to visit you this summer  perhaps in...   \n",
       "1149   I think by summer I’ll pass all my exams so I...   \n",
       "1150   I’m also well  thank you! I like it here  tho...   \n",
       "\n",
       "                                      text_with_context  \\\n",
       "0                              do you listen to albums?   \n",
       "1     Yes I do. Have you listened to Hybrid Theory?d...   \n",
       "2     Yes it is the best selling album of the centur...   \n",
       "3     True. Do you know who Reel Big FIsh are?Yes I ...   \n",
       "4     Yes the band that lost the rights to their own...   \n",
       "...                                                 ...   \n",
       "1146   I’d like to visit you this summer  perhaps in...   \n",
       "1147   I think by summer I’ll pass all my exams so I...   \n",
       "1148   I’m also well  thank you! I like it here  tho...   \n",
       "1149   You know  I’m a Spanish guy. I think by summe...   \n",
       "1150   I like the sun and heat. I’m also well  thank...   \n",
       "\n",
       "                                   text_without_context  \\\n",
       "0                              do you listen to albums?   \n",
       "1         Yes I do. Have you listened to Hybrid Theory?   \n",
       "2     Yes it is the best selling album of the centur...   \n",
       "3              True. Do you know who Reel Big FIsh are?   \n",
       "4     Yes the band that lost the rights to their own...   \n",
       "...                                                 ...   \n",
       "1146   I’d like to visit you this summer  perhaps in...   \n",
       "1147   I think by summer I’ll pass all my exams so I...   \n",
       "1148   I’m also well  thank you! I like it here  tho...   \n",
       "1149                       You know  I’m a Spanish guy.   \n",
       "1150                           I like the sun and heat.   \n",
       "\n",
       "                                text_with_context_clean  \\\n",
       "0                                         listen albums   \n",
       "1                  listened hybrid theory listen albums   \n",
       "2     best selling album century alldo listen albums...   \n",
       "3     true reel big fish listened hybrid theory best...   \n",
       "4     band lost rights music sadyes best selling alb...   \n",
       "...                                                 ...   \n",
       "1146  visit summer perhaps middle july convenient en...   \n",
       "1147  summer pass exams lot free time fine feel comf...   \n",
       "1148  well thank though gets chilly humid sometimes ...   \n",
       "1149  spanish guy summer pass exams lot free time we...   \n",
       "1150  sun heat well thank though gets chilly humid s...   \n",
       "\n",
       "                                 text_with_context_lemm  \\\n",
       "0                                          listen album   \n",
       "1                     listen hybrid theory listen album   \n",
       "2     selling album century alldo listen album liste...   \n",
       "3     true reel big fish listen hybrid theory sellin...   \n",
       "4     band lose right music sadye selling album cent...   \n",
       "...                                                 ...   \n",
       "1146  visit summer perhaps middle july convenient en...   \n",
       "1147  summer pass exam lot free time fine feel comfo...   \n",
       "1148  well thank though chilly humid sometimes visit...   \n",
       "1149  spanish guy summer pass exam lot free time wel...   \n",
       "1150  sun heat well thank though chilly humid someti...   \n",
       "\n",
       "                             text_without_context_clean  \\\n",
       "0                                         listen albums   \n",
       "1                                listened hybrid theory   \n",
       "2                            best selling album century   \n",
       "3                                    true reel big fish   \n",
       "4                            band lost rights music sad   \n",
       "...                                                 ...   \n",
       "1146  visit summer perhaps middle july convenient en...   \n",
       "1147                    summer pass exams lot free time   \n",
       "1148      well thank though gets chilly humid sometimes   \n",
       "1149                                        spanish guy   \n",
       "1150                                           sun heat   \n",
       "\n",
       "                              text_without_context_lemm  \n",
       "0                                          listen album  \n",
       "1                                  listen hybrid theory  \n",
       "2                                 selling album century  \n",
       "3                                    true reel big fish  \n",
       "4                             band lose right music sad  \n",
       "...                                                 ...  \n",
       "1146  visit summer perhaps middle july convenient en...  \n",
       "1147                     summer pass exam lot free time  \n",
       "1148           well thank though chilly humid sometimes  \n",
       "1149                                        spanish guy  \n",
       "1150                                           sun heat  \n",
       "\n",
       "[1151 rows x 12 columns]"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохранение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T22:19:56.907009Z",
     "start_time": "2021-04-14T22:19:56.893045Z"
    }
   },
   "outputs": [],
   "source": [
    "CSV_EXTENSION = '.csv'\n",
    "EXCEL_EXTENSION = '.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T22:19:57.577486Z",
     "start_time": "2021-04-14T22:19:57.557555Z"
    },
    "id": "eoD_Sn6Qa9Oa"
   },
   "outputs": [],
   "source": [
    "def save_dataset(data, file_name, output='csv', start_index=None, end_index=None):\n",
    "    \n",
    "    def save(data, file_name=file_name, output=output):\n",
    "        if output == 'csv':\n",
    "            data.to_csv(file_name + CSV_EXTENSION, index=False)\n",
    "        elif output == 'excel':\n",
    "            data.to_excel(file_name + EXCEL_EXTENSION, index=False)\n",
    "        else:\n",
    "            raise ValueError('unknown type')\n",
    "\n",
    "            \n",
    "    if start_index is None and end_index is None:\n",
    "        saving_data = data\n",
    "    elif start_index is None and end_index is not None:\n",
    "        saving_data = data[:end_index]\n",
    "    elif start_index is not None and end_index is None:\n",
    "        saving_data = data[start_index:]\n",
    "    else:\n",
    "        saving_data = data[start_index:end_index]\n",
    "    \n",
    "    save(saving_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T22:19:58.015214Z",
     "start_time": "2021-04-14T22:19:58.009229Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 1\n",
    "TEST_SIZE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T22:19:58.250585Z",
     "start_time": "2021-04-14T22:19:58.241608Z"
    }
   },
   "outputs": [],
   "source": [
    "data_len = len(data)\n",
    "train_index = int(data_len * TRAIN_SIZE)\n",
    "test_index = int(train_index + data_len * TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T22:19:58.985455Z",
     "start_time": "2021-04-14T22:19:58.948554Z"
    }
   },
   "outputs": [],
   "source": [
    "save_dataset(data, 'preparing_train_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_dataset(data, 'preparing_train', end_index=train_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dataset(data, '../data/other/temp/preparing_test', start_index=train_index, end_index=test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dataset(data, '../data/other/temp/preparing_private_test', start_index=test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dataset_preparing.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
